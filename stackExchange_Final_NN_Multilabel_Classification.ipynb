{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOSl3gvWIXZSLk5txH1NXFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fa3480592d944d2b4484c7f4a113b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fd4a5e8db3e426fa00e9c14d48afb46",
              "IPY_MODEL_2a6cac741e0c49e39ef832552b427134",
              "IPY_MODEL_c29fee39cf3c443a994868af44edd69a"
            ],
            "layout": "IPY_MODEL_c71f7dada421494f9fdb47a6cbfca321"
          }
        },
        "6fd4a5e8db3e426fa00e9c14d48afb46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e598d3c20885487ca0f4f821ae64ed6e",
            "placeholder": "​",
            "style": "IPY_MODEL_ae2d490d3c2748428f2049678a09be60",
            "value": "Pandas Apply: 100%"
          }
        },
        "2a6cac741e0c49e39ef832552b427134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ed71acb3ee491e8cf5e24e5bc4c3eb",
            "max": 47427,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32cd3778da5f4d63838d97c30ede8882",
            "value": 47427
          }
        },
        "c29fee39cf3c443a994868af44edd69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3855eabe31e48d5be2bfdb65e217a59",
            "placeholder": "​",
            "style": "IPY_MODEL_c1bebbdd755a4cdcaee7048c443e4746",
            "value": " 47427/47427 [00:00&lt;00:00, 113318.78it/s]"
          }
        },
        "c71f7dada421494f9fdb47a6cbfca321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e598d3c20885487ca0f4f821ae64ed6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2d490d3c2748428f2049678a09be60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20ed71acb3ee491e8cf5e24e5bc4c3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32cd3778da5f4d63838d97c30ede8882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3855eabe31e48d5be2bfdb65e217a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bebbdd755a4cdcaee7048c443e4746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parimalakettymuthu/MachineLearning-Projects/blob/main/stackExchange_Final_NN_Multilabel_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lD103gpJGRUv"
      },
      "outputs": [],
      "source": [
        "#Defined the autoreload functionality\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imported/installed required packages and defined the google drive access, basepath & added system path to custom-functions\n",
        "import sys\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  !pip install torchtext --upgrade --q\n",
        "  !pip install torchmetrics --q\n",
        "  !pip install --quiet torch-lr-finder --q\n",
        "  !pip install --upgrade wandb --q\n",
        "  !pip install --gensim --q\n",
        "\n",
        "  basepath = '/content/drive/My Drive/NLP'\n",
        "  sys.path.append('/content/drive/My Drive/NLP/custom-functions')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niYpbqdmGee8",
        "outputId": "ce496189-bb97-45ff-9e12-9a060376b3b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --gensim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchmetrics\n",
        "from torchmetrics.classification import MultilabelF1Score, MultilabelHammingDistance\n",
        "from torchmetrics.functional.classification import multilabel_f1_score,multilabel_hamming_distance\n",
        "\n",
        "import joblib\n",
        "import ast\n",
        "import wandb\n",
        "\n",
        "from types import SimpleNamespace\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer as mlb"
      ],
      "metadata": {
        "id": "PnlDottZHGp2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defined the google drive folders for accessing/saving model progress\n",
        "embeddings_folder = Path(basepath)/ 'assignment7/WordEmbeddings'\n",
        "data_folder = Path(basepath)/ 'assignment7/MultiLabel_Classification'\n",
        "model_saving_folder = Path(basepath)/ 'assignment7/NN_MultiLabel_Classification_task3b'\n"
      ],
      "metadata": {
        "id": "e-j3MGnXIv_Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Access the joblib file and load the dataset\n",
        "data_cleaned = data_folder/ \"df_multilabel_hw_cleaned.joblib\"\n",
        "stackExchange_dataset = joblib.load(data_cleaned)"
      ],
      "metadata": {
        "id": "ZUXNMBESJlBz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defined the X & y variables from the dataset\n",
        "X = stackExchange_dataset['cleaned_text'].values\n",
        "y = stackExchange_dataset['Tag_Number'].values"
      ],
      "metadata": {
        "id": "0e72yv8uJweQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installed swifter packages\n",
        "!pip install swifter -qq  "
      ],
      "metadata": {
        "id": "CKvLRqjYJ9YP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81d3d85-55b1-4d82-eb8d-b20d9c075272"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/830.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m830.9/830.9 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installed required packages, and converted Tag_Number using ast module\n",
        "import swifter\n",
        "import ast\n",
        "stackExchange_dataset['Tag_number_list'] = stackExchange_dataset['Tag_Number'].swifter.apply(lambda x: ast.literal_eval(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6fa3480592d944d2b4484c7f4a113b1d",
            "6fd4a5e8db3e426fa00e9c14d48afb46",
            "2a6cac741e0c49e39ef832552b427134",
            "c29fee39cf3c443a994868af44edd69a",
            "c71f7dada421494f9fdb47a6cbfca321",
            "e598d3c20885487ca0f4f821ae64ed6e",
            "ae2d490d3c2748428f2049678a09be60",
            "20ed71acb3ee491e8cf5e24e5bc4c3eb",
            "32cd3778da5f4d63838d97c30ede8882",
            "c3855eabe31e48d5be2bfdb65e217a59",
            "c1bebbdd755a4cdcaee7048c443e4746"
          ]
        },
        "id": "2Sp6rZbSKBUp",
        "outputId": "91b76322-2ae3-4747-82bb-5c86ee89113c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pandas Apply:   0%|          | 0/47427 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fa3480592d944d2b4484c7f4a113b1d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_final = stackExchange_dataset['Tag_number_list'].values"
      ],
      "metadata": {
        "id": "NMAV6a5aKU6q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.preprocessing import MultiLabelBinarizer as mlb\n",
        "y_stackExchange_encoding = mlb().fit_transform(y_final)"
      ],
      "metadata": {
        "id": "w_LBf1tDKX3v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitted the dataset into train, test & valid proportionally\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_sExchange_train, X_valid_test, y_sExchange_train, y_valid_test = train_test_split(X, y_stackExchange_encoding, test_size=0.4, random_state=42)\n",
        "X_sExchange_valid, X_sExchange_test, y_sExchange_valid, y_sExchange_test = train_test_split(X_valid_test, y_valid_test, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "3WQRfaoHKaej"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accessiing binary file from the given folder and loaded the vectors using KeyedVectors\n",
        "from gensim.models import KeyedVectors\n",
        "pretrained_sExchange_file = str(embeddings_folder/ \"model_stackExchange_CBOW.bin\")\n",
        "sExchange_vectors = KeyedVectors.load(pretrained_sExchange_file)"
      ],
      "metadata": {
        "id": "5sz0-6-cKcuW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installed learning rate finder package\n",
        "!pip install torch_lr_finder -qq"
      ],
      "metadata": {
        "id": "msRp53LRKkuP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Learing Rate finder & other custom packages\n",
        "from torch_lr_finder import LRFinder\n",
        "from Trainer_v4 import Trainer\n",
        "from data_preparation_HW7 import *"
      ],
      "metadata": {
        "id": "zqR58BTUKo3R"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the custom packages\n",
        "from ff_sequential_model_v1 import MLPCustom"
      ],
      "metadata": {
        "id": "mfuTxEy8Kwvi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Dataset & Vocab"
      ],
      "metadata": {
        "id": "k_fe2Z8SK8CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Created the respective custom Dataset \n",
        "se_trainset = CustomDataset(X_sExchange_train, y_sExchange_train)\n",
        "se_validset = CustomDataset(X_sExchange_valid, y_sExchange_valid)\n",
        "se_testset = CustomDataset(X_sExchange_test, y_sExchange_test)\n",
        "se_train_subset_indices = random.sample(range(0, len(se_trainset)), len(se_trainset)*0.25)\n",
        "se_train_subset = torch.utils.data.Subset(se_trainset, se_train_subset_indices)\n",
        "#Creating stackexchange vocab\n",
        "stackExchange_vocab = get_vocab(se_trainset, min_freq=2)"
      ],
      "metadata": {
        "id": "Peh49J0jK1AX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting pretrained weights from the generated vocabulary & vectors and the given embedding dimension\n",
        "pretrained_weights, words_found, words_not_found = get_pretrained_weights(\n",
        "    vocab=stackExchange_vocab,\n",
        "    pretrained_vectors=sExchange_vectors,\n",
        "    embedding_dim = 300,\n",
        "    )"
      ],
      "metadata": {
        "id": "ixqPCRHJLqRZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTJJPui7OD-H",
        "outputId": "1c5b5886-7b37-47a8-e859-27c72677a862"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([90287, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pretrained_weights), words_found, words_not_found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Y2BUIjOGfG",
        "outputId": "7369c473-8202-473b-b8f2-0457033058b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, 14664, 75623)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defined the hyperparameters needed for the model \n",
        "hyperparameters = SimpleNamespace(\n",
        "    # for model\n",
        "    EMBED_DIM=300,\n",
        "    VOCAB_SIZE=len(stackExchange_vocab),\n",
        "    OUTPUT_DIM=10,\n",
        "    HIDDEN_SIZES_LIST=[200],\n",
        "    DPROB_LIST=[0.0],\n",
        "    NON_LINEARITY=nn.ReLU(),\n",
        "    BATCH_NORM=False,\n",
        "\n",
        "    # for training\n",
        "    INITIALIZATION ='kaiming',\n",
        "    EPOCHS=20,\n",
        "    BATCH_SIZE=128,\n",
        "    LEARNING_RATE=0.001,\n",
        "    DATASET='IMDB',\n",
        "    ARCHITECTURE='embed_layer-ffn',\n",
        "\n",
        "    # for optimizer\n",
        "    OPTIMIZER='AdamW',\n",
        "    MOMENTUM = 0,\n",
        "    NESTEROV = False,\n",
        "    WEIGHT_DECAY = 0.000,\n",
        "\n",
        "    # gradient clipping\n",
        "    CLIP_TYPE='norm',\n",
        "    CLIP_VALUE=2,\n",
        "\n",
        "    # early stopping\n",
        "    EARLY_STOP_PATIENCE=5,\n",
        "\n",
        "    #scheduler\n",
        "    SCHEDULER = 'None'\n",
        "    )"
      ],
      "metadata": {
        "id": "rPvQYcLcOKmv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the run name and folder"
      ],
      "metadata": {
        "id": "EsNRNmfKOcEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defined the path for saving the project & subsequent model run results\n",
        "project_name = 'Regularization_stackExchange_v4'\n",
        "run_name = 'exp1.3'\n",
        "run_folder = model_saving_folder/project_name/run_name\n",
        "run_folder.mkdir(exist_ok=True, parents=True)\n",
        "log_frequency = 5"
      ],
      "metadata": {
        "id": "siiHWSsXObeP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu0b3v2wOrtm",
        "outputId": "19b75f6f-3f4d-463c-e903-2c8d722cd4dd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/NLP/assignment7/NN_MultiLabel_Classification_task3b/Regularization_stackExchange_v4/exp1.2')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###   Given the parameters and its subsequent runs   \n",
        "\n",
        "# run 1 - based on default initialization\n",
        "# Notes: Final Learning rate was set to 0.01\n",
        "\n",
        "# run 2 - add dropout\n",
        "# hyperparameters.LEARNING_RATE = 0.01   \n",
        "# hyperparameters.DPROB_LIST=[0.5] \n",
        "\n",
        "# run 3 - remove dropout, add weight decay\n",
        "# hyperparameters.WEIGHT_DECAY = 1\n",
        "# hyperparameters.DPROB_LIST=[0] \n",
        "\n",
        "# run 4 - remove dropout, add weight decay\n",
        "# hyperparameters.WEIGHT_DECAY = 0.1\n",
        "\n",
        "# run 5 - increase batch size to 256\n",
        "# hyperparameters.BATCH_SIZE = 256\n",
        "\n",
        "# run 6 - One cyucle scheduler\n",
        "# hyperparameters.LEARNING_RATE = 0.001   \n",
        "# hyperparameters.WEIGHT_DECAY = 10\n",
        "# hyperparameters.SCHEDULER='OneCyclicLR'\n",
        "# hyperparameters.SCHEDULER_MAX_LR=0.01\n",
        "# hyperparameters.SCHEDULER_DIV_FACTOR=25\n",
        "# hyperparameters.SCHEDULER_FINAL_DIV_FACTOR=1e3\n",
        "# hyperparameters.EPOCHS = 10\n",
        "\n",
        "#  run 7 - use pre-trained weights but freeze teh weights - model will \n",
        "# hyperparameters.USE_PRE_TRAINED_WEIGHTS = True\n",
        "# hyperparameters.FREEZE_PRETRAINED = True\n",
        "\n",
        "# run 8 - Unfreeze the weights\n",
        "# hyperparameters.FREEZE_PRETRAINED = False"
      ],
      "metadata": {
        "id": "e--6b0QeOssE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer Configuration"
      ],
      "metadata": {
        "id": "TacRg3OnOziv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix seed value\n",
        "Trainer.set_seed()\n",
        "\n",
        "collate_fn = partial(collate_batch, vocab=stackExchange_vocab)\n",
        "\n",
        "# Data Loader\n",
        "train_loader, valid_loader = get_loaders(trainset=se_trainset, validset=se_validset, \n",
        "                                         batch_size_=hyperparameters.BATCH_SIZE,\n",
        "                                         collate_fn=collate_fn)\n",
        "\n",
        "# cross entropy loss function\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model\n",
        "model_stackExchange = MLPCustom(hyperparameters.EMBED_DIM,\n",
        "                       hyperparameters.VOCAB_SIZE,\n",
        "                       hyperparameters.HIDDEN_SIZES_LIST,\n",
        "                       hyperparameters.DPROB_LIST,\n",
        "                       hyperparameters.OUTPUT_DIM,\n",
        "                       hyperparameters.NON_LINEARITY,\n",
        "                       hyperparameters.BATCH_NORM,  )                     \n",
        "                      #  use_pre_trained_weights =hyperparameters.USE_PRE_TRAINED_WEIGHTS,\n",
        "                      #  pretrained_weights=pretrained_weights, \n",
        "                      #  freeze_pretrained = hyperparameters.FREEZE_PRETRAINED)\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      torch.nn.init.kaiming_normal_(m.weight)\n",
        "      torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "# apply initialization recursively  to all modules\n",
        "if hyperparameters.INITIALIZATION =='kaiming':\n",
        "    model_stackExchange.apply(init_weights)\n",
        "\n",
        "# OPTIMIZERS\n",
        "def get_optimizer():\n",
        "    if hyperparameters.OPTIMIZER == \"SGD\":\n",
        "        optimizer = torch.optim.SGD(\n",
        "            model_stackExchange.parameters(),\n",
        "            lr=hyperparameters.LEARNING_RATE,\n",
        "            momentum=hyperparameters.MOMENTUM,\n",
        "            nesterov=hyperparameters.NESTEROV,\n",
        "            weight_decay = hyperparameters.WEIGHT_DECAY\n",
        "        )\n",
        "    else:\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            model_stackExchange.parameters(), \n",
        "            lr=hyperparameters.LEARNING_RATE,\n",
        "            weight_decay = hyperparameters.WEIGHT_DECAY\n",
        "\n",
        "        )\n",
        "    return optimizer\n",
        "\n",
        "optimizer = get_optimizer()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "7SKUiD1DOymn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_stackExchange"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BVhKjLjQMho",
        "outputId": "46d48a97-51db-41c0-b4d3-460d80156620"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPCustom(\n",
              "  (non_linearity): ReLU()\n",
              "  (embedding): EmbeddingBag(90287, 300, mode='mean')\n",
              "  (module_list): ModuleList(\n",
              "    (0): Linear(in_features=300, out_features=200, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.0, inplace=False)\n",
              "    (3): Linear(in_features=200, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUOIAveaQVW0",
        "outputId": "55d298ba-4918-43f8-854a-843939fa75e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify Trainer"
      ],
      "metadata": {
        "id": "VLf5jUSXQY40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model_stackExchange, optimizer=optimizer,\n",
        "                  criterion=loss_function, device=device)\n",
        "# set loaders\n",
        "trainer.set_loaders(train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "JIZBHmW3QXt7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Trainer based on Hyperparameters"
      ],
      "metadata": {
        "id": "Ld3BNBkhQoNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset Optimizer\n",
        "trainer.set_optimizer(get_optimizer())\n",
        "\n",
        "# set metric -- optional\n",
        "train_metric = MultilabelHammingDistance(num_labels=10)\n",
        "valid_metric = MultilabelHammingDistance(num_labels=10)\n",
        "trainer.set_metric(train_metric.to(device), valid_metric.to(device))\n",
        "\n",
        "# set checkpoint -- OPTIONAL\n",
        "trainer.set_checkpoint(save_path=run_folder,\n",
        "                       save_best=True, save_every_n_epochs=5, save_last_epoch=True)\n",
        "\n",
        "# set early stopping\n",
        "trainer.set_early_stopping(patience = hyperparameters.EARLY_STOP_PATIENCE)\n",
        "\n",
        "# set gradient clipping\n",
        "trainer.set_gradient_clipping(hyperparameters.CLIP_TYPE, hyperparameters.CLIP_VALUE, norm_type=2)\n",
        "\n",
        "# set scheduler\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(trainer.optimizer, patience=hyperparameters.SCHEDULER_PATIENCE,\n",
        "#                                           factor=hyperparameters.SCHEDULER_FACTOR)\n",
        "\n",
        "steps_per_epoch = len(trainer.train_loader)\n",
        "# scheduler = torch.optim.lr_scheduler.OneCycleLR(trainer.optimizer, \n",
        "#                                                 hyperparameters.SCHEDULER_MAX_LR, \n",
        "#                                                 steps_per_epoch=steps_per_epoch,\n",
        "#                                                 epochs=hyperparameters.EPOCHS,\n",
        "#                                                 div_factor=hyperparameters.SCHEDULER_DIV_FACTOR,\n",
        "#                                                 final_div_factor=hyperparameters.SCHEDULER_FINAL_DIV_FACTOR)\n",
        "\n",
        "# trainer.set_lr_scheduler(scheduler=scheduler)"
      ],
      "metadata": {
        "id": "a2w_RmoHQ8g3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set wandb -- OPTIONAL\n",
        "trainer.set_wandb(project_name=project_name,\n",
        "                  run_name=run_name, config=hyperparameters, log_batch=True, log_frequency=log_frequency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "Ahhx3EmgR6dI",
        "outputId": "fb2d4713-ba32-48c9-bef2-5c5b198c599c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230427_011018-i1gsplgj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/parimala/Regularization_stackExchange_v4/runs/i1gsplgj' target=\"_blank\">exp1.2</a></strong> to <a href='https://wandb.ai/parimala/Regularization_stackExchange_v4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/parimala/Regularization_stackExchange_v4' target=\"_blank\">https://wandb.ai/parimala/Regularization_stackExchange_v4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/parimala/Regularization_stackExchange_v4/runs/i1gsplgj' target=\"_blank\">https://wandb.ai/parimala/Regularization_stackExchange_v4/runs/i1gsplgj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity Check"
      ],
      "metadata": {
        "id": "HHeFAaS8R-Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.sanity_check(num_classes=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwwTyU61R9If",
        "outputId": "4b6ee8bf-09d5-4c70-8592-40d15bdf9d5c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/NLP/custom-functions/data_preparation_HW7.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  labels = torch.tensor(labels, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual loss: 0.6994191809309996\n",
            "Expected Theoretical loss: 0.6931471805599453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer Model"
      ],
      "metadata": {
        "id": "5qiWDZ8wSD1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(num_epochs=hyperparameters.EPOCHS, multilabel=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "s-c5azNWSGHU",
        "outputId": "9a3ead06-d2e9-4fd6-a72b-d7f736e2782a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Loss: 0.2381, Train Metric: 0.0916, Train Time: 0:00:24.651279\n",
            "Epoch 1/50 - Val Loss: 0.1516, Val Metric: 0.0554, Val Time: 0:00:06.710697\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 2/50 - Train Loss: 0.1270, Train Metric: 0.0458, Train Time: 0:00:25.454594\n",
            "Epoch 2/50 - Val Loss: 0.1234, Val Metric: 0.0448, Val Time: 0:00:06.050181\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 3/50 - Train Loss: 0.0999, Train Metric: 0.0354, Train Time: 0:00:25.289278\n",
            "Epoch 3/50 - Val Loss: 0.1115, Val Metric: 0.0400, Val Time: 0:00:06.982883\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 4/50 - Train Loss: 0.0820, Train Metric: 0.0281, Train Time: 0:00:24.892560\n",
            "Epoch 4/50 - Val Loss: 0.1050, Val Metric: 0.0375, Val Time: 0:00:06.037698\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 5/50 - Train Loss: 0.0685, Train Metric: 0.0230, Train Time: 0:00:24.989752\n",
            "Epoch 5/50 - Val Loss: 0.1023, Val Metric: 0.0356, Val Time: 0:00:06.991926\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 6/50 - Train Loss: 0.0574, Train Metric: 0.0187, Train Time: 0:00:25.871150\n",
            "Epoch 6/50 - Val Loss: 0.0993, Val Metric: 0.0343, Val Time: 0:00:06.036615\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 7/50 - Train Loss: 0.0481, Train Metric: 0.0155, Train Time: 0:00:27.340609\n",
            "Epoch 7/50 - Val Loss: 0.0991, Val Metric: 0.0335, Val Time: 0:00:06.903158\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 8/50 - Train Loss: 0.0403, Train Metric: 0.0127, Train Time: 0:00:25.489541\n",
            "Epoch 8/50 - Val Loss: 0.1007, Val Metric: 0.0332, Val Time: 0:00:05.991868\n",
            "Current Learning rate is 0.001\n",
            "\n",
            "Epoch 9/50 - Train Loss: 0.0336, Train Metric: 0.0103, Train Time: 0:00:27.247376\n",
            "Epoch 9/50 - Val Loss: 0.1014, Val Metric: 0.0327, Val Time: 0:00:08.142159\n",
            "Current Learning rate is 0.001\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-69be3cce92ec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultilabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/NLP/custom-functions/Trainer_v4.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, multilabel, threshold)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             train_loss, train_metric = self._run_epoch(\n\u001b[0m\u001b[1;32m    409\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/NLP/custom-functions/Trainer_v4.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, loader, training, multilabel, threshold)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             loss = self._run_batch(\n\u001b[0m\u001b[1;32m    326\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultilabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             )\n",
            "\u001b[0;32m/content/drive/My Drive/NLP/custom-functions/Trainer_v4.py\u001b[0m in \u001b[0;36m_run_batch\u001b[0;34m(self, step_number, inputs, targets, metric, multilabel, threshold, training, len_loader)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             batch_metric = self._get_batch_metric(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultilabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             )\n",
            "\u001b[0;32m/content/drive/My Drive/NLP/custom-functions/Trainer_v4.py\u001b[0m in \u001b[0;36m_get_batch_metric\u001b[0;34m(self, outputs, targets, multilabel, metric, threshold)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbatch_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_full_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_reduce_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36m_forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# calculate batch state and compute batch value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected all tensors to be on\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/classification/stat_scores.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;34m\"\"\"Update state with predictions and targets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             _multilabel_stat_scores_tensor_validation(\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultidim_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/functional/classification/stat_scores.py\u001b[0m in \u001b[0;36m_multilabel_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_labels, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;31m# Check that target only contains [0,1] values or value in ignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m     \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unique_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    798\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         output, inverse_indices, counts = torch._unique2(\n\u001b[0m\u001b[1;32m    800\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.plot_history()"
      ],
      "metadata": {
        "id": "3hnEHF3MSUds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot([lr for list_ in trainer.learning_rates[1:] for lr in list_ ])"
      ],
      "metadata": {
        "id": "U_2Ml9lkSWer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Accuracy & Predictions"
      ],
      "metadata": {
        "id": "cft-iGXMSg-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = get_test_loaders(se_testset, batch_size_=hyperparameters.BATCH_SIZE,\n",
        "                               collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "bodF_I2WSgC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.timestamp"
      ],
      "metadata": {
        "id": "yjJwL4XESo6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'checkpoint_' + str(trainer.timestamp) + '_best.pt'\n",
        "trainer.load_checkpoint(run_folder /file)"
      ],
      "metadata": {
        "id": "vr8-EU2hSrIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the prediction and accuracy for the test dataset\n",
        "predictions_test, target_test = trainer.predict(\n",
        "    test_loader, return_targets=True, multilabel=True)\n",
        "predictions_train, target_train = trainer.predict(\n",
        "    train_loader, return_targets=True, multilabel=True)\n",
        "predictions_valid, target_valid = trainer.predict(\n",
        "    valid_loader, return_targets=True, multilabel=True)"
      ],
      "metadata": {
        "id": "rbgiCGLTStgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = multilabel_hamming_distance\n",
        "hd_train = metric(predictions_train, target_train, num_labels=10)\n",
        "hd_valid = metric(predictions_valid, target_valid, num_labels=10)\n",
        "hd_test = metric(predictions_test, target_test, num_labels=10)\n"
      ],
      "metadata": {
        "id": "EaTFxYHySuC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Hammo=imng Distance\n",
        "print('Test hamming distance', hd_test )\n",
        "print('Train hamming distance', hd_train )\n",
        "print('Valid hamming distance', hd_valid )"
      ],
      "metadata": {
        "id": "jVkbccxpS28m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional.classification import multilabel_accuracy"
      ],
      "metadata": {
        "id": "fJvboSzMS9_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = multilabel_accuracy\n",
        "acc_train = metric(predictions_train, target_train, num_labels=10)\n",
        "acc_valid = metric(predictions_valid, target_valid, num_labels=10)\n",
        "acc_test = metric(predictions_test, target_test, num_labels=10)\n"
      ],
      "metadata": {
        "id": "wS0mpj-kS-lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Hammo=imng Distance\n",
        "print('Test accuracy', acc_test)\n",
        "print('Train accuracy', acc_train)\n",
        "print('Valid accuracy', acc_valid)"
      ],
      "metadata": {
        "id": "mI_NfMvKTAp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy', 1- acc_test)\n",
        "print('Train accuracy', 1- acc_train)\n",
        "print('Valid accuracy', 1- acc_valid)"
      ],
      "metadata": {
        "id": "Vx-Je2BgTD5F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}