{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuFdnmzWL5wwrChVHp4jJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parimalakettymuthu/MachineLearning-Projects/blob/main/Multiclass_Classification_assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 537,
      "metadata": {
        "id": "uwfUJqYkNAO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1534c54-6f13-4143-847b-da65cb9a7ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.path.append('/content/drive/MyDrive/NLP/custom-functions')"
      ],
      "metadata": {
        "id": "n_ca_2ktNolQ"
      },
      "execution_count": 538,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  !pip install -U swifter -qq\n",
        "  !pip install -U nltk -qq\n",
        "  !pip install -U spacy -qq\n",
        "  !python -m spacy download en_core_web_sm -qq\n",
        "  !pip install torchtext --upgrade\n",
        "  base_path = '/content/drive/MyDrive/NLP/assignment5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCabWijON3X5",
        "outputId": "e31aec84-83b5-40e0-c59a-388c6a790391"
      },
      "execution_count": 539,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-04-02 22:14:33.634773: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 22:14:34.601509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-02 22:14:36.362478: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (0.15.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.91)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.101)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.10.3.66)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.10.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.14.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.6.0->torchtext) (1.26.15)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (67.6.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.25.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as inn\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "metadata": {
        "id": "4UCObZsEOAuP"
      },
      "execution_count": 540,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = Path(base_path)\n",
        "for entries in data_folder.iterdir():\n",
        "  print(entries.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0yT4KHrQQ8Y",
        "outputId": "4c521874-07b5-40a9-e0f6-4c09e29e0234"
      },
      "execution_count": 541,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiclass_hw_cleaned.csv\n",
            "Multiclass_Classification_assignment5.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stackExchange1 = pd.read_csv(data_folder/ 'multiclass_hw_cleaned.csv', encoding = 'ISO-8859-1')\n",
        "print(stackExchange1.shape)\n",
        "print(stackExchange1.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn5ARljiShrr",
        "outputId": "9b6fe83d-c509-483b-a802-348807bd2d22"
      },
      "execution_count": 542,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(188878, 6)\n",
            "   Unnamed: 0                                     Title  \\\n",
            "0           0   detail disclosure indicator on UIButton   \n",
            "1           1  hello world fails to show up in emulator   \n",
            "\n",
            "                                                Body  \\\n",
            "0  <p>Is there a simple way to place a detail dis...   \n",
            "1  <p>I followed Hello World tutorial exactly.  E...   \n",
            "\n",
            "                                        cleaned_text     Tags  \\\n",
            "0  detail disclosure indicator uibutton simple wa...   iphone   \n",
            "1  hello world fail emulator follow hello world t...  android   \n",
            "\n",
            "   Tag_Number_final  \n",
            "0                 8  \n",
            "1                 4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stackExchange = pd.DataFrame().assign(cleaned_text=stackExchange1['cleaned_text'], Tag_Number_final=stackExchange1['Tag_Number_final'])\n",
        "print(stackExchange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW1_DFXlS-pF",
        "outputId": "8f484722-5fac-4cb2-e662-a3521baaf7ca"
      },
      "execution_count": 543,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             cleaned_text  Tag_Number_final\n",
            "0       detail disclosure indicator uibutton simple wa...                 8\n",
            "1       hello world fail emulator follow hello world t...                 4\n",
            "2       jshint throw possible strict violation line tr...                 3\n",
            "3       programmatically bound column invisible try da...                 9\n",
            "4       edittext get focus soft keyboard android home ...                 4\n",
            "...                                                   ...               ...\n",
            "188873  reload tab activity tab change reload activity...                 4\n",
            "188874  learning index loop list contain list inner li...                 7\n",
            "188875  module pattern | private access pass reference...                 3\n",
            "188876  listener homebutton android   possible duplica...                 4\n",
            "188877  php optimize multiple conditional loop multipl...                 2\n",
            "\n",
            "[188878 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stackExchange.dropna(inplace=True)\n",
        "print(stackExchange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnMHXsYFhiam",
        "outputId": "a59e0611-1f7a-4826-aecf-8ecca1cbe0dc"
      },
      "execution_count": 544,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             cleaned_text  Tag_Number_final\n",
            "0       detail disclosure indicator uibutton simple wa...                 8\n",
            "1       hello world fail emulator follow hello world t...                 4\n",
            "2       jshint throw possible strict violation line tr...                 3\n",
            "3       programmatically bound column invisible try da...                 9\n",
            "4       edittext get focus soft keyboard android home ...                 4\n",
            "...                                                   ...               ...\n",
            "188873  reload tab activity tab change reload activity...                 4\n",
            "188874  learning index loop list contain list inner li...                 7\n",
            "188875  module pattern | private access pass reference...                 3\n",
            "188876  listener homebutton android   possible duplica...                 4\n",
            "188877  php optimize multiple conditional loop multipl...                 2\n",
            "\n",
            "[188874 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train and test sets (80/20 split)\n",
        "SExchangeTrain, test_val = train_test_split(stackExchange, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split train set into train and validation sets (50/50 split)\n",
        "SExchangeTest, SExchangeVal = train_test_split(test_val, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the shapes & percentage of split of the resulting datasets\n",
        "print(\"Train set shape: \", SExchangeTrain.shape, \"Split %: \", len(SExchangeTrain)/len(stackExchange))\n",
        "print(\"Validation set shape: \", SExchangeVal.shape,\"Split %: \", len(SExchangeVal)/len(stackExchange))\n",
        "print(\"Test set shape: \", SExchangeTest.shape, \"Split %: \", len(SExchangeTest)/len(stackExchange))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJESKH-IUoYl",
        "outputId": "75000e33-8366-4005-a766-16931bf4f1a2"
      },
      "execution_count": 545,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape:  (151099, 2) Split %:  0.7999989410930038\n",
            "Validation set shape:  (18888, 2) Split %:  0.1000031767209886\n",
            "Test set shape:  (18887, 2) Split %:  0.09999788218600761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_SExchangeTrain = SExchangeTrain[\"cleaned_text\"]\n",
        "X_SExchangeTest = SExchangeTest[\"cleaned_text\"]\n",
        "X_SExchangeValid = SExchangeVal[\"cleaned_text\"]\n",
        "\n",
        "Y_SExchangeTrain = SExchangeTrain[\"Tag_Number_final\"]\n",
        "Y_SExchangeTest = SExchangeTest[\"Tag_Number_final\"]\n",
        "Y_SExchangeValid = SExchangeVal[\"Tag_Number_final\"]"
      ],
      "metadata": {
        "id": "jGkAnIy1fkVR"
      },
      "execution_count": 546,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "!pip install wandb -qq\n",
        "import wandb\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zB1VXi2iWjOg"
      },
      "execution_count": 547,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Vectors using Tfidf"
      ],
      "metadata": {
        "id": "qiPbtwjid5PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorizer = TfidfVectorizer(\n",
        " #   stop_words='english', min_df=4, max_features=5000).fit(X_SExchangeTrain)\n",
        "#X_SEtrain_vec = vectorizer.transform(X_SExchangeTrain)\n",
        "#X_SEvalid_vec = vectorizer.transform(X_SExchangeValid)\n",
        "#X_SEtest_vec = vectorizer.transform(X_SExchangeTest)"
      ],
      "metadata": {
        "id": "3snImmxudgXW"
      },
      "execution_count": 548,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create PyTorch Tensors"
      ],
      "metadata": {
        "id": "VShDEqegiMDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensors of data\n",
        "#X_SEtrain_Tensor = torch.tensor(X_SEtrain_vec.toarray()).float()\n",
        "#X_SEvalid_Tensor = torch.tensor(X_SEvalid_vec.toarray()).float()\n",
        "#X_SEtest_Tensor = torch.tensor(X_SEtest_vec.toarray()).float()\n",
        "\n",
        "#y_SEtrain_Tensor = torch.tensor(np.array(Y_SExchangeTrain)).long()\n",
        "#y_SEvalid_Tensor = torch.tensor(np.array(Y_SExchangeValid)).long()\n",
        "#y_SEtest_Tensor = torch.tensor(np.array(Y_SExchangeTest)).long()\n"
      ],
      "metadata": {
        "id": "FPlrCdRihdfy"
      },
      "execution_count": 549,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create PyTorch Dataset"
      ],
      "metadata": {
        "id": "GyPMTu95lejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensor dataset\n",
        "#SETrain_set = torch.utils.data.TensorDataset(X_SEtrain_Tensor, y_SEtrain_Tensor)\n",
        "#SETest_set = torch.utils.data.TensorDataset(X_SEtest_Tensor, y_SEtest_Tensor)\n",
        "#SEValid_set = torch.utils.data.TensorDataset(X_SEvalid_Tensor, y_SEvalid_Tensor)"
      ],
      "metadata": {
        "id": "J9f8FPamePcb"
      },
      "execution_count": 550,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom class"
      ],
      "metadata": {
        "id": "9CleI-fhb8pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomClass(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y \n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text = self.X.iloc[idx]\n",
        "    labels = self.y.iloc[idx]\n",
        "    tup = (labels, text)\n",
        "    return tup"
      ],
      "metadata": {
        "id": "lGO1HxWHb2Iq"
      },
      "execution_count": 551,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEtrain_dataset = CustomClass(X_SExchangeTrain, Y_SExchangeTrain)\n",
        "i=0\n",
        "for i, (x,y) in enumerate(SEtrain_dataset):\n",
        "  if(i<=10):\n",
        "    print(i, x,y)\n",
        "    i+=1\n",
        "  else:\n",
        "    break\n",
        "SEtrain_dataset.__getitem__([2])\n",
        "#SEtrain_dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP_DPkMtc8Vs",
        "outputId": "33b98bd4-4d8c-44cc-b55a-644a5dcaddb8"
      },
      "execution_count": 552,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 7 python read ini file python want transform joomla ini language file sql joomla ini file actually miss section example translation rawconfigparser job demand section construct temp file dummy section name      fout = tempfile namedtemporaryfile(delete = true      fin = file(self._infilename r      fout.write(\"[all]\\n      f              fout.write(f      config = configparser rawconfigparser(allow_no_value = true           c config.items(\"all              self._ini2sql(unicode(c[0]).upper unicode('de unicode(c[1][1:-1   def elegant solution tip pythonic\n",
            "1 2 php data difference give fatal error date value come database want calculate difference today date database date date come database 2012 06 11 18:20:40   use code value      echo date('y m d h s      echo $ result['dt_pub_date   write code $ val = date('y m d h s ->diff($result['dt_pub_date   get error fatal error member function diff non object   thank\n",
            "2 4 convert arraylist message convert arraylist message convert msg arraylist arraylist extractdata = arraylist   opposite right message msg=(message arraylist  \n",
            "3 0 select certain text text file enter text box hi sql script text file follow create view dbo].[budget_change-22 select projectname projectnumber location client       openrowset('sqlncli server = aabb1089\\abcworkss_sto;uid = abcworkss;pwd = abcdef                         set nocount on;set fmtonly off;exec abcworks_sto sp_budget_444 38 workchanged_444        script select server value aabb1089\\abcworkss_sto uid value(abcwork pwd value(abcdef replace text box edit create new text file different\n",
            "4 0 .net know main method application clr identify main method application order begin execution exactly sequence operation clr take execute .exe file\n",
            "5 0 add 48 string number string c like string only_number   assign value = 40 check only_number[0 52 check only_number[1 48 add 48 character current position suggest\n",
            "6 4 android finish acitivitie application 10 activity activity contain click button activity finished(it mean like logout gmail 2 step work 1 clear stack intent.addflags(intent flag_activity_clear_top activity call 2 button click listener    implement anybody help thank\n",
            "7 4 android alignment image accord device size have image button linear layout fit fine large device come small device image come line small device align properly landscape screen portrait mode   xml code          < linearlayout              android id=\"@+id linearlayout7              android layout_width=\"fill_parent              android layout_height=\"wrap_content android layout_marginleft=\"5dp android layout_marginright=\"5dp android layout_marginbottom=\"5dp android gravity=\"left android layout_gravity=\"left android fitssystemwindows=\"true >               < imagebutton                  android id=\"@+id stopservicebutton                  android layout_width=\"wrap_content                  android layout_height=\"wrap_content                  android src=\"@drawable stop_service_button_selector android background=\"@null android layout_gravity=\"left android paddingbottom=\"5dp android paddingright=\"5dp android paddingtop=\"5dp\"/ >               < imagebutton                  android id=\"@+id calibratebutton                  android layout_width=\"wrap_content                  android layout_height=\"wrap_content                  android src=\"@drawable calibrate_button_selector android background=\"@null android layout_gravity=\"left android padding=\"5dp\"/ >               < imagebutton                  android id=\"@+id donebutton                  android layout_width=\"wrap_content                  android layout_height=\"wrap_content                  android src=\"@drawable done_button_selector android background=\"@null android layout_gravity=\"left android padding=\"5dp\"/ >           < /linearlayout >  \n",
            "8 4 android application d android application d programatically method communicate application d\n",
            "9 7 replace nth occurrence list string build function kind new python problem write script element ex str replacefrom replaceto n find character replace nth occurrence    example > > > replaeceit(\"mississippi s l 2 mislissippi > > > replaeceit(\"mississippi s l 0 mississippi   n 2 code change second s l n=0 dosen't nything honestly know implement n equation code far n def replaceit(str replacefrom replaceto      new=      letter str          letter== replacefrom              new = new+replaceto                        new = new+lett      return new  \n",
            "10 4 play sound broadcastreceiver able message box broadcastreceiver play sound instead\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(83942    4\n",
              " Name: Tag_Number_final, dtype: int64,\n",
              " 83942    convert arraylist message convert arraylist me...\n",
              " Name: cleaned_text, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 552
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEtest_dataset = CustomClass(X_SExchangeTest, Y_SExchangeTest)\n",
        "i=0\n",
        "for i, (x,y) in enumerate(SEtest_dataset):\n",
        "  if(i<=10):\n",
        "    print(i, x,y)\n",
        "    i+=1\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj56h-6J16gj",
        "outputId": "c27620ae-0cbc-41ac-c0e4-b7b7fecc3fc5"
      },
      "execution_count": 553,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 4 android tab support v4l2 usb host functionality need know name android tablet v4l2 support host functionality suppose plug usb camera tablet functionality thank lot advance\n",
            "1 2 filename php $ str = /d file shop/7c0ea5b0b96a490a9c78255ddb559943.jpg   filename path thank lot\n",
            "2 6 c++ ` my_map[i = ` std::map < int int > my_map my_map[0 =   my_map[0 0 1 undefined\n",
            "3 0 code path return value method public bool userexistsactivedir     try            const int ads_uf_accountdisable = 0x00000002        directoryentry de = new directoryentry        de path = ldap://domainname        directorysearcher objadsearcher = new directorysearcher(de        de authenticationtype = authenticationtypes secure         objadsearcher searchroot = de        objadsearcher filter = samaccountname= + txtusername text +        searchresult result = objadsearcher findone         result tostring =                  int flag = convert toint32(results properties[\"useraccountcontrol\"][0].tostre           //results properties[\"useraccountcontrol\"][0].tostring().equals(\"514           convert toboolean(flag ads_uf_accountdisable                        return false                                            return true                          catch exception ex            lblerror text = ex message tostring        return false                  go wrong say miss return far know return statement\n",
            "4 1 convert app java version 6 5 solution convert java'a high application create   netbean ide 6.5.1 low version java version 5  \n",
            "5 8 integrate apple payment gate way iphone want integrate apple payment gateway iphone app i.e suppose user want purchase gold online store payment apple payment gatway anybody know advise\n",
            "6 1 java string.equalsignorecase work develop small application java following condition true body know actual reason public int foo   string stitle = title stitle.equalsignorecase(mycustomobject.stitle      return 5      return 6   return 6 run debug mode see string contain value try swap position string like mycustomobject.stitle.equalsignorecase(stitle   work\n",
            "7 3 javascript import datum browser page url hash way provide datum browser page example want save user setting server retreive user pc hash possible generate url ask user save url shortcut usb flash way\n",
            "8 4 user google market account user market account account install application google market code\n",
            "9 1 display result java need display result program number person associate    example tom=20 john=10 paul=0 2 1 tom 2 john a=20 b=0 c=0 2 1 tom 2 score think statement get messy long way easy idea   thank > = b    > = c max= b > = c min= c min= b   max= c min= b b > = c   max= b > = c min= c min= max= c > = b min= b min=    kind idea  \n",
            "10 0 external file project dataset file want include visual studio 2010 c project it(need suggestion read fileinfo project pc different developer good hardcode path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEvalid_dataset = CustomClass(X_SExchangeValid, Y_SExchangeValid)\n",
        "i=0\n",
        "for i, (x,y) in enumerate(SEvalid_dataset):\n",
        "  if(i<=10):\n",
        "    print(i, x,y)\n",
        "    i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF4hxACo2Ahf",
        "outputId": "efc58b9a-8a25-47cb-abd0-362cc91086b9"
      },
      "execution_count": 554,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3 cross domain ajax activexobject ie activexobject object ie submit cross domain request\n",
            "1 5 wrap script function professional approach right work little training code try code semi fixed page element result   $ document).ready(function      var elementposition = $ header\").offset      var elementheight = $ header\").outerheight      $ header\").before(\"<div id='placeholder style='display height + elementheight + px'></div >      $ window).scroll(function          checkattached(\"#header            function checkattached(element          var windowdepth = $ window).scrolltop          windowdepth > =              $ element).addclass(\"attached              $ placeholder\").css(\"display block                       $ element).removeclass(\"attache              $ placeholder\").css(\"display                 thing happy solution like little flexible goal independent function allow address page element like attachthis(element   right have trouble scroll event inside function know good solution overwrite elementposition current solution define outside function clean course expect deliver well script maybe push right direction point suitable technique love know professional approach task\n",
            "2 1 confusing loop java let look follow day day example java package loop   final public class main        public static void main(string args                 long temp=1000000000           while(temp--!=0                       temp-=temp++              system.out.println(\"inside loop = + temp                   system.out.println(\"outside loop = + temp         simple code loop iterate local variable temp type long contain large value 1000000000   statement system.out.println(\"inside loop = + temp display inside loop = 0 statement system.out.println(\"outside loop = + temp display outside loop = -1\n",
            "3 4 android augmented reality application greeting want develop ar app want match real time image store database app want display marker recognize image brief introduction search lot find way start kindly provide nice tutorial ar start app try create\n",
            "4 4 retrieve image url custom list view android image url code work properly get image app get crash error show exact solution help code level 06 20 19:16:55.254 d dalvikvm(335 gc_external_alloc free 62 k 52 free 2589k/5379 k external 1942k/2137 k pause 59ms 06 20 19:16:56.164 d dalvikvm(335 gc_external_alloc free 506 k 52 free 2902k/6023 k external 2342k/2858 k pause 43ms 06 20 19:16:56.194 e dalvikvm heap(335 28959048 byte external allocation large process 06 20 19:16:56.233 e graphicsjni(335 vm will let allocate 28959048 byte 06 20 19:16:56.233 d dalvikvm(335 gc_for_malloc free 184 k 55 free 2717k/6023 k external 2342k/2858 k pause 25ms 06 20 19:16:56.233 d skia(335 decoder->decode return false 06 20 19:16:56.233 d androidruntime(335 shut vm 06 20 19:16:56.233 w dalvikvm(335 threadid=1 thread exit uncaught exception group=0x40015560 06 20 19:16:56.273 e androidruntime(335 fatal exception main 06 20 19:16:56.273 e androidruntime(335 outofmemoryerror bitmap size exceed vm budget 06 20 19:16:56.273 e androidruntime(335   bitmapfactory.nativedecodestream(native method 06 20 19:16:56.273 e androidruntime(335   bitmapfactory.decodestream(bitmapfactory.java:470 06 20 19:16:56.273 e androidruntime(335   bitmapfactory.decoderesourcestream(bitmapfactory.java:336 06 20 19:16:56.273 e androidruntime(335   drawable.createfromresourcestream(drawable.java:697 06 20 19:16:56.273 e androidruntime(335   drawable.createfromstream(drawable.java:657 06 20 19:16:56.273 e androidruntime(335   customadaptor loadimagefromweboperations(customadaptor.java:97 06 20 19:16:56.273 e androidruntime(335   customadaptor.getview(customadaptor.java:73 06 20 19:16:56.273 e androidruntime(335   abslistview.obtainview(abslistview.java:1409 06 20 19:16:56.273 e androidruntime(335   listview.measureheightofchildren(listview.java:1216 06 20 19:16:56.273 e androidruntime(335   listview.onmeasure(listview.java:1127 06 20 19:16:56.273 e androidruntime(335   view.measure(view.java:8313 06 20 19:16:56.273 e androidruntime(335   viewgroup.measurechildwithmargins(viewgroup.java:3138 06 20 19:16:56.273 e androidruntime(335   linearlayout.measurechildbeforelayout(linearlayout.java:1017 06 20 19:16:56.273 e androidruntime(335   linearlayout.measurevertical(linearlayout.java:386 06 20 19:16:56.273 e androidruntime(335   linearlayout.onmeasure(linearlayout.java:309 06 20 19:16:56.273 e androidruntime(335   view.measure(view.java:8313 06 20 19:16:56.273 e androidruntime(335   viewgroup.measurechildwithmargins(viewgroup.java:3138 06 20 19:16:56.273 e androidruntime(335   framelayout.onmeasure(framelayout.java:250 06 20 19:16:56.273 e androidruntime(335   view.measure(view.java:8313 06 20 19:16:56.273 e androidruntime(335   linearlayout.measurevertical(linearlayout.java:531 06 20 19:16:56.273 e androidruntime(335   linearlayout.onmeasure(linearlayout.java:309 06 20 19:16:56.273 e androidruntime(335   view.measure(view.java:8313 06 20 19:16:56.273 e androidruntime(335   viewgroup.measurechildwithmargins(viewgroup.java:3138 06 20 19:16:56.273 e androidruntime(335   framelayout.onmeasure(framelayout.java:250 06 20 19:16:56.273 e androidruntime(335   view.measure(view.java:8313 06 20 19:16:56.273 e androidruntime(335   viewroot.performtraversals(viewroot.java:839 06 20 19:16:56.273 e androidruntime(335   viewroot.handlemessage(viewroot.java:1859 06 20 19:16:56.273 e androidruntime(335   handler.dispatchmessage(handler.java:99 06 20 19:16:56.273 e androidruntime(335   looper.loop(looper.java:123 06 20 19:16:56.273 e androidruntime(335   activitythread.main(activitythread.java:3683 06 20 19:16:56.273 e androidruntime(335   method.invokenative(native method 06 20 19:16:56.273 e androidruntime(335   method.invoke(method.java:507 06 20 19:16:56.273 e androidruntime(335   zygoteinit$methodandargscaller.run(zygoteinit.java:839 06 20 19:16:56.273 e androidruntime(335   zygoteinit.main(zygoteinit.java:597 06 20 19:16:56.273 e androidruntime(335   nativestart.main(native method 06 20 19:21:56.314 process(335 send signal pid 335 sig 9 06 20 19:47:17.034 d dalvikvm(369 gc_external_alloc free 63 k 52 free 2589k/5379 k external 1942k/2137 k pause 47ms 06 20 19:47:17.794 d dalvikvm(369 gc_external_alloc free 506 k 52 free 2902k/6023 k external 2342k/2858 k pause 43ms 06 20 19:47:17.824 e dalvikvm heap(369 28959048 byte external allocation large process 06 20 19:47:17.864 e graphicsjni(369 vm will let allocate 28959048 byte 06 20 19:47:17.864 d dalvikvm(369 gc_for_malloc free 184 k 55 free 2717k/6023 k external 2342k/2858 k pause 27ms 06 20 19:47:17.864 d skia(369 decoder->decode return false 06 20 19:47:17.864 d androidruntime(369 shut vm 06 20 19:47:17.864 w dalvikvm(369 threadid=1 thread exit uncaught exception group=0x40015560 06 20 19:47:17.884 e androidruntime(369 fatal exception main 06 20 19:47:17.884 e androidruntime(369 outofmemoryerror bitmap size exceed vm budget 06 20 19:47:17.884 e androidruntime(369   bitmapfactory.nativedecodestream(native method 06 20 19:47:17.884 e androidruntime(369   bitmapfactory.decodestream(bitmapfactory.java:470 06 20 19:47:17.884 e androidruntime(369   bitmapfactory.decoderesourcestream(bitmapfactory.java:336 06 20 19:47:17.884 e androidruntime(369   drawable.createfromresourcestream(drawable.java:697 06 20 19:47:17.884 e androidruntime(369   drawable.createfromstream(drawable.java:657 06 20 19:47:17.884 e androidruntime(369   customadaptor loadimagefromweboperations(customadaptor.java:97 06 20 19:47:17.884 e androidruntime(369   customadaptor.getview(customadaptor.java:73 06 20 19:47:17.884 e androidruntime(369   abslistview.obtainview(abslistview.java:1409 06 20 19:47:17.884 e androidruntime(369   listview.measureheightofchildren(listview.java:1216 06 20 19:47:17.884 e androidruntime(369   listview.onmeasure(listview.java:1127 06 20 19:47:17.884 e androidruntime(369   view.measure(view.java:8313 06 20 19:47:17.884 e androidruntime(369   viewgroup.measurechildwithmargins(viewgroup.java:3138 06 20 19:47:17.884 e androidruntime(369   linearlayout.measurechildbeforelayout(linearlayout.java:1017 06 20 19:47:17.884 e androidruntime(369   linearlayout.measurevertical(linearlayout.java:386 06 20 19:47:17.884 e androidruntime(369   linearlayout.onmeasure(linearlayout.java:309 06 20 19:47:17.884 e androidruntime(369   view.measure(view.java:8313 06 20 19:47:17.884 e androidruntime(369   viewgroup.measurechildwithmargins(viewgroup.java:3138 06 20 19:47:17.884 e androidruntime(369   framelayout.onmeasure(framelayout.java:250 06 20 19:47:17.884 e androidruntime(369   view.measure(view.java:8313 06 20 19:47:17.884 e androidruntime(369   linearlayout.measurevertical(linearlayout.java:531 06 20 19:47:17.884 e androidruntime(369   linearlayout.onmeasure(linearlayout.java:309 06 20 19:47:17.884 e androidruntime(369   view.measure(view.java:8313 06 20 19:47:17.884 e androidruntime(369   viewgroup.measurechildwithmargins(viewgroup.java:3138 06 20 19:47:17.884 e androidruntime(369   framelayout.onmeasure(framelayout.java:250 06 20 19:47:17.884 e androidruntime(369   view.measure(view.java:8313 06 20 19:47:17.884 e androidruntime(369   viewroot.performtraversals(viewroot.java:839 06 20 19:47:17.884 e androidruntime(369   viewroot.handlemessage(viewroot.java:1859 06 20 19:47:17.884 e androidruntime(369   handler.dispatchmessage(handler.java:99 06 20 19:47:17.884 e androidruntime(369   looper.loop(looper.java:123 06 20 19:47:17.884 e androidruntime(369   activitythread.main(activitythread.java:3683 06 20 19:47:17.884 e androidruntime(369   method.invokenative(native method 06 20 19:47:17.884 e androidruntime(369   method.invoke(method.java:507 06 20 19:47:17.884 e androidruntime(369   zygoteinit$methodandargscaller.run(zygoteinit.java:839 06 20 19:47:17.884 e androidruntime(369   zygoteinit.main(zygoteinit.java:597 06 20 19:47:17.884 e androidruntime(369   nativestart.main(native method  \n",
            "5 4 android spinner widget develop new kind app android phone problem spinner widget think class vars realy know real problem code public class bhac extend activity      string tzids = new string[10000 string stext   override public void oncreate(bundle savedinstancestate      super.oncreate(savedinstancestate      setcontentview(r.layout.bhac       try               tzids = timezone.getavailableids           spinner spinner = spinner findviewbyid(r.id.spinner1          arrayadapter < string > spinnerarrayadapter = new arrayadapter < string>(this android r.layout.simple_spinner_dropdown_item tzids          spinnerarrayadapter.setdropdownviewresource(android r.layout.simple_spinner_dropdown_item          spinner.setselection(1          spinner.setadapter(spinnerarrayadapter           try                         spinner.setonitemselectedlistener(new adapterview onitemselectedlistener                                public void onitemselected(adapterview < > parent view view int pos long d                                         stext= tzids[po                       simpledateformat formatter = new simpledateformat(\"yyyy mm dd't'hh mm ss sss'z                      formatter.settimezone(timezone.gettimezone(\"utc                       string timestamp = formatter.format(timezone.gettimezone(stext                       textview t = textview)findviewbyid(r.id.textview2                      t.settext(timestamp                                    public void onnothingselected(adapterview < > parent                                                                   catch exception x                       context context = getapplicationcontext              charsequence text =   android exception bhac + x              int duration = toast length_short               toast toast = toast.maketext(context text duration                           log.e whwjdakdjkajkldjskkkkkk dadada + x            logcat 05 06 19:53:50.950 e global(334 deprecated thread method support 05 06 19:53:50.950 e global(334 unsupportedoperationexception 05 06 19:53:50.950 e global(334   vmthread.stop(vmthread.java:85 05 06 19:53:50.950 e global(334   thread.stop(thread.java:1280 05 06 19:53:50.950 e global(334   thread.stop(thread.java:1247 05 06 19:53:50.950 e global(334   smaleactivity$1.run(smaleactivity.java:58 05 06 19:53:51.748 d dalvikvm(334 gc_external_alloc free 62 k 53 free 2569k/5379 k external 2034k/2137 k pause 98ms 05 06 19:56:36.559 d androidruntime(334 shut vm 05 06 19:56:36.559 w dalvikvm(334 threadid=1 thread exit uncaught exception group=0x40015560 05 06 19:56:36.659 e androidruntime(334 fatal exception main 05 06 19:56:36.659 e androidruntime(334 illegalargumentexception 05 06 19:56:36.659 e androidruntime(334   dateformat.format(dateformat.java:365 05 06 19:56:36.659 e androidruntime(334   format.format(format.java:93 05 06 19:56:36.659 e androidruntime(334   bhac$1.onitemselected(bhac.java:62 05 06 19:56:36.659 e androidruntime(334   adapterview.fireonselected(adapterview.java:871 05 06 19:56:36.659 e androidruntime(334   adapterview.access$200(adapterview.java:42 05 06 19:56:36.659 e androidruntime(334   adapterview$selectionnotifier.run(adapterview.java:837 05 06 19:56:36.659 e androidruntime(334   handler.handlecallback(handler.java:587 05 06 19:56:36.659 e androidruntime(334   handler.dispatchmessage(handler.java:92 05 06 19:56:36.659 e androidruntime(334   looper.loop(looper.java:123 05 06 19:56:36.659 e androidruntime(334   activitythread.main(activitythread.java:3683 05 06 19:56:36.659 e androidruntime(334   method.invokenative(native method 05 06 19:56:36.659 e androidruntime(334   method.invoke(method.java:507 05 06 19:56:36.659 e androidruntime(334   zygoteinit$methodandargscaller.run(zygoteinit.java:839 05 06 19:56:36.659 e androidruntime(334   zygoteinit.main(zygoteinit.java:597 05 06 19:56:36.659 e androidruntime(334   nativestart.main(native method   idea\n",
            "6 6 access private member variable class instance think possible instance class allow access private member copy constructor fact copy constructor reason allow break encapsulation\n",
            "7 4 text activity button activity want know text edittext activity b text button activity a. want press enter button activity b text edittext replace text button activity a. think like       public void pressenter view v      edittext et = edittext findviewbyid(r.id.edittext1      string t = et.gettext().tostring      button p1_button = button)findviewbyid(r.id.button1      p1_button.settext(t   not know id button activity want set text\n",
            "8 2 php function call returned stop run code study user php code right understand learn well   code user class   code block format like   if(!$this->isloggedin      //do stuff   code like $ this->isloggedin      return false   function couple time return value   question return call run code   like end script function    case run $ this->isloggedin          return false   continue run code   function   < php private function logout($redir = true      $ this->isloggedin          return false       $ this->obj->session->sess_destroy       $ this->iscookieloggedin               setcookie('user time()-36000          setcookie('pass time()-36000           $ redir          return       header('location .$this->homepageurl      die >  \n",
            "9 4 unable build eclipse library project adt update main project mainapp develop android eclipse use facebook android sdk library fblib separate eclipse project project property check library project property > android section mainapp fblib add library work fine   need create new version mainapp use different database file asset subdirectory create new eclipse project newapp setup mainapp library project property > android   work fine late adt update get error try build run newapp conversion dalvik format fail error 1 mainapp uncheck library project property > android build mainapp regular application work fine search multiple jar file project directory update proguard 4.8beta delete add jar build path remove export add export delete dependency add lib directory clean restart reboot pretty google turn avail   work fine adt 16 confused add library project application incorporate library project deprecate working\n",
            "10 6 prevent function return pointer go scope open directory opendir return dir want reuse dir constantly object   originaly open directory constructor store pointer private variable obviously fail soon constructor end pointer scope memory free question directory reference class reopen time   try copy dir type complaint dir fully define   doubt figure dir define copy constructor anyways   way scope\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Vocab"
      ],
      "metadata": {
        "id": "XdfLvKcibZfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createVocab(Dataset):\n",
        "  counter = Counter()\n",
        "  for (label, line) in Dataset:\n",
        "    counter.update(str(line).split())\n",
        "  my_vocab = vocab(counter, min_freq=5)\n",
        "  # get mapping of words to index\n",
        "  my_vocab.get_stoi()\n",
        "  # insert '<unk>' token to represent any unknown word\n",
        "  my_vocab.insert_token('<unk>', 0)\n",
        "  # set the default index to zero\n",
        "  # thus any uknown word will be represented b index 0 or token '<unk>'\n",
        "  my_vocab.set_default_index(0)\n",
        "  return my_vocab\n"
      ],
      "metadata": {
        "id": "g7UXq_UUbYpR"
      },
      "execution_count": 555,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#global SETrain_vocab, SETest_vocab, SEValid_vocab\n",
        "SETrain_vocab = createVocab(SEtrain_dataset)\n",
        "SETest_vocab = createVocab(SEtest_dataset)\n",
        "SEValid_vocab = createVocab(SEvalid_dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "o3LjUZD5-AOJ"
      },
      "execution_count": 556,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SETrain_vocab"
      ],
      "metadata": {
        "id": "djFJGP3I_JZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08febfcb-102d-4726-ad98-b4a6f5f940e2"
      },
      "execution_count": 557,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocab()"
            ]
          },
          "metadata": {},
          "execution_count": 557
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create collate_batch function"
      ],
      "metadata": {
        "id": "uTLvN2f7Bqif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a lambda function objects that will be used to get the indices of words from vocab\n",
        "def text_pipeline(x, vocab):\n",
        "    \"\"\"Converts text to a list of indices using a vocabulary dictionary\"\"\"\n",
        "    return [vocab[token] for token in str(x).split()]"
      ],
      "metadata": {
        "id": "Opzi3AHWY-Pn"
      },
      "execution_count": 558,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch,vocab):\n",
        "    labels, texts = zip(*batch)\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "    #if \n",
        "    list_of_list_of_indices = [text_pipeline(text, vocab) for text in texts]\n",
        "    \n",
        "    offsets = [0] + [len(i) for i in list_of_list_of_indices]\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    texts = torch.cat([torch.tensor(i, dtype=torch.int64) for i in list_of_list_of_indices])\n",
        "    return labels, texts, offsets"
      ],
      "metadata": {
        "id": "3Oc1ngAaIAAx"
      },
      "execution_count": 559,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create DataLoaders"
      ],
      "metadata": {
        "id": "5tDmsVFLmAa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initiale the batch size \n",
        "\n",
        "\n",
        "# create DataLoader now\n",
        "torch.manual_seed(0)\n",
        "batch_size = 256\n",
        "SEtrain_loader = torch.utils.data.DataLoader(dataset=SEtrain_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           collate_fn=lambda batch: collate_batch(batch, SETrain_vocab)\n",
        "                                           )\n",
        "\n",
        "SEvalid_loader = torch.utils.data.DataLoader(dataset=SEvalid_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           collate_fn=lambda batch: collate_batch(batch, SEValid_vocab)\n",
        "                                           )\n",
        "SEtest_loader = torch.utils.data.DataLoader(dataset=SEtest_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           collate_fn=lambda batch: collate_batch(batch, SETest_vocab)\n",
        "                                           )\n"
      ],
      "metadata": {
        "id": "6K6PmifCl8W3"
      },
      "execution_count": 560,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label, text, offsets in SEtrain_loader:\n",
        "  print(label.size()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEcpg-sUONto",
        "outputId": "e67e704c-3727-437b-9f11-3fb99d5420c0"
      },
      "execution_count": 576,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "model = nn.EmbeddingBag(len(SETrain_vocab), 300)"
      ],
      "metadata": {
        "id": "wMzwW_bCgNvT"
      },
      "execution_count": 562,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets=[]\n",
        "for label, text, offsets in SEtrain_loader:\n",
        "    #output = model(text, offsets)\n",
        "    #print('Output')\n",
        "    #print(output)\n",
        "    #print(output.shape)\n",
        "    #print('='*75)\n",
        "    targets.append(label)\n"
      ],
      "metadata": {
        "id": "vBU8VubcgW1z"
      },
      "execution_count": 563,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cHECKING MAX INDEX -- TESTING PURPOSE ONLY \n",
        "max_target_idx = -1\n",
        "for label, text, offsets in SEtrain_loader:\n",
        "    targets.append(label)\n",
        "    max_target_in_batch = max(label)\n",
        "    if max_target_in_batch > max_target_idx:\n",
        "        max_target_idx = max_target_in_batch\n",
        "print(\"Maximum target index: \", max_target_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNp0zybOt2BX",
        "outputId": "45b30e13-3dae-467b-e824-89edaa2219c1"
      },
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum target index:  tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label, text, offsets in SEtest_loader: #SEtrain_loader:\n",
        "    label_list += label.tolist()\n",
        "\n",
        "unique_labels = set(label_list)\n",
        "print(len(unique_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0eoOZFWy1Uf",
        "outputId": "9f863f3f-ba0d-4281-9d34-4c7b5049bb25"
      },
      "execution_count": 565,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "lJq1oZooaDD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLPCustom(nn.Module):\n",
        "    def __init__(self, vocab, embed_dim=300, n_hidden1=200, n_hidden2=100, n_outs=10, dropout1=0.5, dropout2=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.EmbeddingBag(len(vocab),300)\n",
        "\n",
        "        self.hidden_layer1 = nn.Linear(embed_dim, n_hidden1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=dropout1)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(n_hidden1)\n",
        "\n",
        "        self.hidden_layer2 = nn.Linear(n_hidden1, n_hidden2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(p=dropout2)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(n_hidden2)\n",
        "\n",
        "        #self.output_layer = nn.Linear(n_hidden2, n_outs)\n",
        "        self.output_layer = nn.Linear(n_hidden2,10)\n",
        "\n",
        "    def forward(self, texts, offsets, vocab):\n",
        "        # input: tensor of shape (batch_size, seq_len)\n",
        "        # offsets: tensor of shape (batch_size,) containing the starting indices of each sequence in the input tensor\n",
        "\n",
        "        embedded = self.embedding(texts, offsets)\n",
        "        # embedded: tensor of shape (batch_size, embed_dim)\n",
        "\n",
        "        h1 = self.hidden_layer1(embedded)\n",
        "        h1 = self.relu1(h1)\n",
        "        h1 = self.dropout1(h1)\n",
        "        h1 = self.batchnorm1(h1)\n",
        "        # h1: tensor of shape (batch_size, n_hidden1)\n",
        "\n",
        "        h2 = self.hidden_layer2(h1)\n",
        "        h2 = self.relu2(h2)\n",
        "        h2 = self.dropout2(h2)\n",
        "        h2 = self.batchnorm2(h2)\n",
        "        # h2: tensor of shape (batch_size, n_hidden2)\n",
        "\n",
        "        ypred = self.output_layer(h2)\n",
        "        # ypred: tensor of shape (batch_size, n_outs)\n",
        "\n",
        "        return ypred"
      ],
      "metadata": {
        "id": "9halWKCvn1ra"
      },
      "execution_count": 566,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a new project\n",
        "wandb.init(name=\"imdb_shallow_non_seq\", project='nlps23_L7')\n",
        "#20efc82737d336646269a333588441a0c04c4c0d        --API Key\n",
        "# Initialize number of epochs, learning rate and batch size\n",
        "learning_rate = 0.2\n",
        "wandb.log({'learning_rate': learning_rate})\n",
        "epochs = 20\n",
        "\n",
        "# device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#n_inputs = train_set.tensors[0].shape[1]\n",
        "\n",
        "\n",
        "model = MLPCustom(SETrain_vocab, embed_dim=300, n_hidden1=200, n_hidden2=100, n_outs=10, dropout1=0.5, dropout2=0.5)\n",
        "\n",
        "#model = MLPCustom(n_inputs, n_hidden1, n_hidden2,n_outputs, non_linearity, bias=True)\n",
        "\n",
        "# loss_function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "31VWRnu5CTZu",
        "outputId": "0a9cc581-fffa-4f48-9196-e0a63143c345"
      },
      "execution_count": 567,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:f7f1mwm1) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.2</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">imdb_shallow_non_seq</strong> at: <a href='https://wandb.ai/parimala/nlps23_L7/runs/f7f1mwm1' target=\"_blank\">https://wandb.ai/parimala/nlps23_L7/runs/f7f1mwm1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230402_221016-f7f1mwm1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:f7f1mwm1). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230402_221553-xw8ckdje</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/parimala/nlps23_L7/runs/xw8ckdje' target=\"_blank\">imdb_shallow_non_seq</a></strong> to <a href='https://wandb.ai/parimala/nlps23_L7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/parimala/nlps23_L7' target=\"_blank\">https://wandb.ai/parimala/nlps23_L7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/parimala/nlps23_L7/runs/xw8ckdje' target=\"_blank\">https://wandb.ai/parimala/nlps23_L7/runs/xw8ckdje</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom class to train, predict accuracy"
      ],
      "metadata": {
        "id": "1EARBHrkN0D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import wandb\n",
        "\n",
        "def step(texts,offsets,vocab, model, device,loss_function=None, optimizer=None):\n",
        "    \"\"\" \n",
        "    Helper function for processing a batch of data.\n",
        "    Input: inputs, targets, model, loss function, optimizer (optional)\n",
        "    Output: loss, predicted outputs, and number of correct predictions\n",
        "    \"\"\"\n",
        "    #model = model.to(device)\n",
        "    # Move inputs and targets to the device\n",
        "    #texts = texts.to(device)\n",
        "    #vocab = vocab.to(device)\n",
        "    #offsets = offsets.to(device)\n",
        "\n",
        "    # Step 1: Forward Pass: Compute model's predictions\n",
        "    outputs = model(texts, offsets,vocab)\n",
        "\n",
        "    # Step 2: Compute loss\n",
        "    if loss_function:\n",
        "        loss = loss_function(outputs, offsets)\n",
        "\n",
        "    # Step 3: Compute accuracy\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct = (predicted == offsets).sum().item()\n",
        "\n",
        "    # Step 4: Backward pass and update parameters if optimizer is given\n",
        "    if optimizer is not None:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if loss_function:\n",
        "        return loss, outputs, correct\n",
        "    else:\n",
        "        return outputs, correct\n",
        "\n",
        "\n",
        "def train_epoch(train_loader, model, device, loss_function, optimizer, train_vocab_len):\n",
        "    \"\"\" \n",
        "    Function for training the model for one epoch.\n",
        "    Input: iterator for train dataset, loss function, model, optimizer (optional)\n",
        "    Output: train loss and accuracy for the epoch\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Initialize train_loss and train_correct for the epoch\n",
        "    running_train_loss = 0\n",
        "    running_train_correct = 0\n",
        "\n",
        "    # Iterate over batches from the dataset using train_loader\n",
        "    for batch in train_loader:\n",
        "        targets,texts, offsets = batch[0], batch[1], batch[2]\n",
        "        \n",
        "        # Send the batch to the device\n",
        "        targets = targets.to(device)\n",
        "        texts = texts.to(device)\n",
        "        offsets = offsets.to(device)\n",
        "        # Process the batch\n",
        "        loss, _, correct = step(texts, offsets, vocab, model, device, \n",
        "                                loss_function, optimizer)\n",
        "\n",
        "        # Add batch loss and accuracy to running total\n",
        "        running_train_loss += loss.item()\n",
        "        running_train_correct += correct\n",
        "\n",
        "    # Calculate mean train loss and accuracy for the epoch\n",
        "    train_loss = running_train_loss / len(train_loader)\n",
        "    train_acc = running_train_correct / len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def val_epoch(valid_loader, model, device, loss_function, valid_vocab_len):\n",
        "    \"\"\" \n",
        "    Function for validating the model for one epoch.\n",
        "    Input: iterator for validation dataset, loss function, model\n",
        "    Output: validation loss and accuracy for the epoch\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize val_loss and val_correct for the epoch\n",
        "    running_val_loss = 0\n",
        "    running_val_correct = 0\n",
        "\n",
        "    # Iterate over batches from the dataset using valid_loader\n",
        "    with torch.no_grad():\n",
        "        for targets, texts, offsets in valid_loader:\n",
        "            # Process the batch\n",
        "            loss, _, correct = step(\n",
        "                texts, offsets, vocab, model, device, loss_function, optimizer=None)\n",
        "\n",
        "            # Add batch loss and accuracy to running total\n",
        "            running_val_loss += loss.item()\n",
        "            running_val_correct += correct\n",
        "\n",
        "    # Calculate mean validation loss and accuracy for the epoch\n",
        "    val_loss = running_val_loss / len(valid_loader)\n",
        "    val_acc = running_val_correct / len(valid_loader.dataset)\n",
        "\n",
        "    return val_loss, val_acc\n",
        "\n",
        "\n",
        "def train(train_loader, valid_loader, model, optimizer, loss_function, epochs, device, train_vocab, valid_vocab):\n",
        "    \"\"\" \n",
        "    Function for training the model and plotting the graph for train & validation loss vs epoch.\n",
        "    Input: iterator for train and validation datasets, model, optimizer, loss function, number of epochs, device\n",
        "    Output: train loss and accuracy history, validation loss and accuracy history\n",
        "    \"\"\"\n",
        "\n",
        "    # Create lists to store train and val loss and accuracy at each epoch\n",
        "    train_loss_history = []\n",
        "    valid_loss_history = []\n",
        "    train_acc_history = []\n",
        "    valid_acc_history = []\n",
        "    train_vocab_len = len(train_vocab)\n",
        "    valid_vocab_len = len(valid_vocab)\n",
        "    # Iterate for the given number of epochs\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Train the model for one epoch and get train loss and accuracy\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            train_loader, model, device, loss_function, optimizer,train_vocab_len)\n",
        "\n",
        "        # Validate the model and get validation loss and accuracy\n",
        "        valid_loss, valid_acc = val_epoch(\n",
        "            valid_loader, model, device, loss_function, valid_vocab_len)\n",
        "\n",
        "        # Append the loss and accuracy to their respective lists\n",
        "        train_loss_history.append(train_loss)\n",
        "        train_acc_history.append(train_acc)\n",
        "        valid_loss_history.append(valid_loss)\n",
        "        valid_acc_history.append(valid_acc)\n",
        "\n",
        "        # Log the train and valid loss and accuracy to WandB\n",
        "        wandb.log({\"Train Loss\": train_loss, \"Train Accuracy\": train_acc})\n",
        "        wandb.log({\"Valid Loss\": valid_loss, \"Valid Accuracy\": valid_acc})\n",
        "\n",
        "        # Print the train and valid loss and accuracy for the epoch\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(\n",
        "            f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc*100:.2f}%\")\n",
        "        print(\n",
        "            f\"Valid Loss: {valid_loss:.4f} | Valid Accuracy: {valid_acc*100:.2f}%\")\n",
        "        print()\n",
        "\n",
        "    return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history\n",
        "\n",
        "\n",
        "def get_acc_pred(data_loader, model, device):\n",
        "    \"\"\" \n",
        "    Function to get predictions and accuracy for a given data using a trained model\n",
        "    Input: data iterator, model, device\n",
        "    Output: predictions and accuracy for the given dataset\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Create empty tensors to store predictions and actual labels\n",
        "    predictions = torch.Tensor().to(device)\n",
        "    y = torch.Tensor().to(device)\n",
        "\n",
        "    # Iterate over batches from data iterator\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            # Process the batch to get the loss, outputs, and correct predictions\n",
        "            outputs, _ = step(inputs, targets, model,\n",
        "                              device, loss_function=None, optimizer=None)\n",
        "\n",
        "            # Choose the label with maximum probability\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Add the predicted labels and actual labels to their respective tensors\n",
        "            predictions = torch.cat((predictions, predicted))\n",
        "            y = torch.cat((y, targets.to(device)))\n",
        "\n",
        "    # Calculate accuracy by comparing the predicted and actual labels\n",
        "    accuracy = (predictions == y).float().mean()\n",
        "\n",
        "    # Return tuple containing predictions and accuracy\n",
        "    return predictions, accuracy"
      ],
      "metadata": {
        "id": "tYYyTeGHNyjB"
      },
      "execution_count": 568,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 569,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2022-10-02T11:18:59.063373Z",
          "iopub.status.busy": "2022-10-02T11:18:59.063161Z",
          "iopub.status.idle": "2022-10-02T11:19:10.388677Z",
          "shell.execute_reply": "2022-10-02T11:19:10.388079Z",
          "shell.execute_reply.started": "2022-10-02T11:18:59.063359Z"
        },
        "id": "LckLb_9bhZDw",
        "outputId": "ba4b84cd-5cbc-4020-b9cd-9500506883d2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-569-e00b5e149a3e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train(SEtrain_loader,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                                      \u001b[0mSEvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                                      \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                                      \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                                      \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-568-ae62de726fbe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, valid_loader, model, optimizer, loss_function, epochs, device, train_vocab, valid_vocab)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Train the model for one epoch and get train loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         train_loss, train_acc = train_epoch(\n\u001b[0m\u001b[1;32m    126\u001b[0m             train_loader, model, device, loss_function, optimizer,train_vocab_len)\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-568-ae62de726fbe>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, device, loss_function, optimizer, train_vocab_len)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Process the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         loss, _, correct = step(texts, offsets, vocab, model, device, \n\u001b[0m\u001b[1;32m     62\u001b[0m                                 loss_function, optimizer)\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-568-ae62de726fbe>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(texts, offsets, vocab, model, device, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Step 2: Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Step 3: Compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 53 is out of bounds."
          ]
        }
      ],
      "source": [
        "train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train(SEtrain_loader,\n",
        "                                                                                     SEvalid_loader,\n",
        "                                                                                     model,\n",
        "                                                                                     optimizer,\n",
        "                                                                                     loss_function,\n",
        "                                                                                     epochs,\n",
        "                                                                                     device,SETrain_vocab,SEValid_vocab)\n",
        " "
      ]
    }
  ]
}