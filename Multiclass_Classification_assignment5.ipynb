{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqfFzelurxrPQEGfgfK2ll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parimalakettymuthu/MachineLearning-Projects/blob/main/Multiclass_Classification_assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uwfUJqYkNAO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99363ee-d180-412f-e84e-4f08a7a1b55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.path.append('/content/drive/MyDrive/NLP/custom-functions')"
      ],
      "metadata": {
        "id": "n_ca_2ktNolQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  !pip install -U swifter -qq\n",
        "  !pip install -U nltk -qq\n",
        "  !pip install -U spacy -qq\n",
        "  !python -m spacy download en_core_web_sm -qq\n",
        "  !pip install torchtext --upgrade\n",
        "  base_path = '/content/drive/MyDrive/NLP/assignment5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCabWijON3X5",
        "outputId": "1ace9b2e-66dd-425b-c1a0-139295cf35a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-31 22:08:57.106503: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-31 22:08:59.403703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-03-31 22:09:02.555510: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (0.15.1)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (0.6.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (10.9.0.58)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.10.7)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.14.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.91)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.4.91)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (11.7.101)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.6.0->torchtext) (1.26.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (67.6.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as inn\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "metadata": {
        "id": "4UCObZsEOAuP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = Path(base_path)\n",
        "for entries in data_folder.iterdir():\n",
        "  print(entries.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0yT4KHrQQ8Y",
        "outputId": "9103f0bf-2be0-46f8-8e62-c1e4ed00077d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiclass_hw_cleaned.csv\n",
            "Multiclass_Classification_assignment5.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stackExchange1 = pd.read_csv(data_folder/ 'multiclass_hw_cleaned.csv', encoding = 'ISO-8859-1')\n",
        "print(stackExchange1.shape)\n",
        "print(stackExchange1.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn5ARljiShrr",
        "outputId": "e4b0d13b-9d79-4569-b8ee-e427d1e4000a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(188878, 6)\n",
            "   Unnamed: 0                                     Title  \\\n",
            "0           0   detail disclosure indicator on UIButton   \n",
            "1           1  hello world fails to show up in emulator   \n",
            "\n",
            "                                                Body  \\\n",
            "0  <p>Is there a simple way to place a detail dis...   \n",
            "1  <p>I followed Hello World tutorial exactly.  E...   \n",
            "\n",
            "                                        cleaned_text     Tags  \\\n",
            "0  detail disclosure indicator uibutton simple wa...   iphone   \n",
            "1  hello world fail emulator follow hello world t...  android   \n",
            "\n",
            "   Tag_Number_final  \n",
            "0                 8  \n",
            "1                 4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stackExchange = pd.DataFrame().assign(cleaned_text=stackExchange1['cleaned_text'], Tag_Number_final=stackExchange1['Tag_Number_final'])\n",
        "print(stackExchange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW1_DFXlS-pF",
        "outputId": "793bae3f-717b-4852-9fec-b1e09dc6b898"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             cleaned_text  Tag_Number_final\n",
            "0       detail disclosure indicator uibutton simple wa...                 8\n",
            "1       hello world fail emulator follow hello world t...                 4\n",
            "2       jshint throw possible strict violation line tr...                 3\n",
            "3       programmatically bound column invisible try da...                 9\n",
            "4       edittext get focus soft keyboard android home ...                 4\n",
            "...                                                   ...               ...\n",
            "188873  reload tab activity tab change reload activity...                 4\n",
            "188874  learning index loop list contain list inner li...                 7\n",
            "188875  module pattern | private access pass reference...                 3\n",
            "188876  listener homebutton android   possible duplica...                 4\n",
            "188877  php optimize multiple conditional loop multipl...                 2\n",
            "\n",
            "[188878 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stackExchange.dropna(inplace=True)\n",
        "print(stackExchange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnMHXsYFhiam",
        "outputId": "f10c891b-ec72-485a-9a4f-47bcf8568928"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             cleaned_text  Tag_Number_final\n",
            "0       detail disclosure indicator uibutton simple wa...                 8\n",
            "1       hello world fail emulator follow hello world t...                 4\n",
            "2       jshint throw possible strict violation line tr...                 3\n",
            "3       programmatically bound column invisible try da...                 9\n",
            "4       edittext get focus soft keyboard android home ...                 4\n",
            "...                                                   ...               ...\n",
            "188873  reload tab activity tab change reload activity...                 4\n",
            "188874  learning index loop list contain list inner li...                 7\n",
            "188875  module pattern | private access pass reference...                 3\n",
            "188876  listener homebutton android   possible duplica...                 4\n",
            "188877  php optimize multiple conditional loop multipl...                 2\n",
            "\n",
            "[188874 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train and test sets (80/20 split)\n",
        "SExchangeTrain, test_val = train_test_split(stackExchange, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split train set into train and validation sets (50/50 split)\n",
        "SExchangeTest, SExchangeVal = train_test_split(test_val, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the shapes & percentage of split of the resulting datasets\n",
        "print(\"Train set shape: \", SExchangeTrain.shape, \"Split %: \", len(SExchangeTrain)/len(stackExchange))\n",
        "print(\"Validation set shape: \", SExchangeVal.shape,\"Split %: \", len(SExchangeVal)/len(stackExchange))\n",
        "print(\"Test set shape: \", SExchangeTest.shape, \"Split %: \", len(SExchangeTest)/len(stackExchange))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJESKH-IUoYl",
        "outputId": "adc74415-ec90-4b9d-88e6-2d015c10d133"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape:  (151099, 2) Split %:  0.7999989410930038\n",
            "Validation set shape:  (18888, 2) Split %:  0.1000031767209886\n",
            "Test set shape:  (18887, 2) Split %:  0.09999788218600761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_SExchangeTrain = SExchangeTrain[\"cleaned_text\"].values\n",
        "X_SExchangeTest = SExchangeTest[\"cleaned_text\"].values\n",
        "X_SExchangeValid = SExchangeVal[\"cleaned_text\"].values\n",
        "\n",
        "Y_SExchangeTrain = SExchangeTrain[\"Tag_Number_final\"].values\n",
        "Y_SExchangeTest = SExchangeTest[\"Tag_Number_final\"].values\n",
        "Y_SExchangeValid = SExchangeVal[\"Tag_Number_final\"].values"
      ],
      "metadata": {
        "id": "jGkAnIy1fkVR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "!pip install wandb -qq\n",
        "import wandb\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zB1VXi2iWjOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b4bc35-0a96-4481-ce97-298c7cb20abe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Vectors using Tfidf"
      ],
      "metadata": {
        "id": "qiPbtwjid5PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorizer = TfidfVectorizer(\n",
        " #   stop_words='english', min_df=4, max_features=5000).fit(X_SExchangeTrain)\n",
        "#X_SEtrain_vec = vectorizer.transform(X_SExchangeTrain)\n",
        "#X_SEvalid_vec = vectorizer.transform(X_SExchangeValid)\n",
        "#X_SEtest_vec = vectorizer.transform(X_SExchangeTest)"
      ],
      "metadata": {
        "id": "3snImmxudgXW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create PyTorch Tensors"
      ],
      "metadata": {
        "id": "VShDEqegiMDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensors of data\n",
        "#X_SEtrain_Tensor = torch.tensor(X_SEtrain_vec.toarray()).float()\n",
        "#X_SEvalid_Tensor = torch.tensor(X_SEvalid_vec.toarray()).float()\n",
        "#X_SEtest_Tensor = torch.tensor(X_SEtest_vec.toarray()).float()\n",
        "\n",
        "#y_SEtrain_Tensor = torch.tensor(np.array(Y_SExchangeTrain)).long()\n",
        "#y_SEvalid_Tensor = torch.tensor(np.array(Y_SExchangeValid)).long()\n",
        "#y_SEtest_Tensor = torch.tensor(np.array(Y_SExchangeTest)).long()\n"
      ],
      "metadata": {
        "id": "FPlrCdRihdfy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create PyTorch Dataset"
      ],
      "metadata": {
        "id": "GyPMTu95lejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensor dataset\n",
        "#SETrain_set = torch.utils.data.TensorDataset(X_SEtrain_Tensor, y_SEtrain_Tensor)\n",
        "#SETest_set = torch.utils.data.TensorDataset(X_SEtest_Tensor, y_SEtest_Tensor)\n",
        "#SEValid_set = torch.utils.data.TensorDataset(X_SEvalid_Tensor, y_SEvalid_Tensor)"
      ],
      "metadata": {
        "id": "J9f8FPamePcb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom class"
      ],
      "metadata": {
        "id": "9CleI-fhb8pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomClass(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y \n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text = self.X.iloc(idx)\n",
        "    labels = self.y.iloc(idx)\n",
        "    tup = (text, labels)\n",
        "    return tup"
      ],
      "metadata": {
        "id": "lGO1HxWHb2Iq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tran_dataset = customClass(X_SExchangeTrain, Y_SExchangeTrain)"
      ],
      "metadata": {
        "id": "oP_DPkMtc8Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Vocab"
      ],
      "metadata": {
        "id": "XdfLvKcibZfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def createVocab(,):\n",
        "\n",
        "  #return "
      ],
      "metadata": {
        "id": "g7UXq_UUbYpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create DataLoaders"
      ],
      "metadata": {
        "id": "5tDmsVFLmAa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initiale the batch size \n",
        "#batch_size = 256\n",
        "\n",
        "#Trainset dataloader\n",
        "#SETrain_Loader = torch.utils.data.DataLoader(dataset=SETrain_set,\n",
        "                                           #batch_size=batch_size,\n",
        "                                           #shuffle=True)\n",
        "#Testset dataloader\n",
        "#SETest_Loader = torch.utils.data.DataLoader(dataset=SETest_set,\n",
        "                                          # batch_size=batch_size,\n",
        "                                           #shuffle=True)\n",
        "#Validset dataloader\n",
        "#SEValid_Loader = torch.utils.data.DataLoader(dataset=SEValid_set,\n",
        "                                           #batch_size=batch_size,\n",
        "                                           #shuffle=True)\n"
      ],
      "metadata": {
        "id": "6K6PmifCl8W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9halWKCvn1ra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}